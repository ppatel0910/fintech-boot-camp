{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting Net Prophet\n",
    "\n",
    "You’re a growth analyst at [MercadoLibre](http://investor.mercadolibre.com/investor-relations). With over 200 million users, MercadoLibre is the most popular e-commerce site in Latin America. You've been tasked with analyzing the company's financial and user data in clever ways to make the company grow. So, you want to find out if the ability to predict search traffic can translate into the ability to successfully trade the stock.\n",
    "\n",
    "Instructions\n",
    "\n",
    "This section divides the instructions for this Challenge into four steps and an optional fifth step, as follows:\n",
    "\n",
    "* Step 1: Find unusual patterns in hourly Google search traffic\n",
    "\n",
    "* Step 2: Mine the search traffic data for seasonality\n",
    "\n",
    "* Step 3: Relate the search traffic to stock price patterns\n",
    "\n",
    "* Step 4: Create a time series model with Prophet\n",
    "\n",
    "* Step 5 (optional): Forecast revenue by using time series models\n",
    "\n",
    "The following subsections detail these steps.\n",
    "\n",
    "## Step 1: Find Unusual Patterns in Hourly Google Search Traffic\n",
    "\n",
    "The data science manager asks if the Google search traffic for the company links to any financial events at the company. Or, does the search traffic data just present random noise? To answer this question, pick out any unusual patterns in the Google search data for the company, and connect them to the corporate financial events.\n",
    "\n",
    "To do so, complete the following steps:\n",
    "\n",
    "1. Read the search data into a DataFrame, and then slice the data to just the month of May 2020. (During this month, MercadoLibre released its quarterly financial results.) Use hvPlot to visualize the results. Do any unusual patterns exist?\n",
    "\n",
    "2. Calculate the total search traffic for the month, and then compare the value to the monthly median across all months. Did the Google search traffic increase during the month that MercadoLibre released its financial results?\n",
    "\n",
    "## Step 2: Mine the Search Traffic Data for Seasonality\n",
    "\n",
    "Marketing realizes that they can use the hourly search data, too. If they can track and predict interest in the company and its platform for any time of day, they can focus their marketing efforts around the times that have the most traffic. This will get a greater return on investment (ROI) from their marketing budget.\n",
    "\n",
    "To that end, you want to mine the search traffic data for predictable seasonal patterns of interest in the company. To do so, complete the following steps:\n",
    "\n",
    "1. Group the hourly search data to plot the average traffic by the day of the week (for example, Monday vs. Friday).\n",
    "\n",
    "2. Using hvPlot, visualize this traffic as a heatmap, referencing the `index.hour` as the x-axis and the `index.dayofweek` as the y-axis. Does any day-of-week effect that you observe concentrate in just a few hours of that day?\n",
    "\n",
    "3. Group the search data by the week of the year. Does the search traffic tend to increase during the winter holiday period (weeks 40 through 52)?\n",
    "\n",
    "## Step 3: Relate the Search Traffic to Stock Price Patterns\n",
    "\n",
    "You mention your work on the search traffic data during a meeting with people in the finance group at the company. They want to know if any relationship between the search data and the company stock price exists, and they ask if you can investigate.\n",
    "\n",
    "To do so, complete the following steps:\n",
    "\n",
    "1. Read in and plot the stock price data. Concatenate the stock price data to the search data in a single DataFrame.\n",
    "\n",
    "2. Market events emerged during the year of 2020 that many companies found difficult. But, after the initial shock to global financial markets, new customers and revenue increased for e-commerce platforms. Slice the data to just the first half of 2020 (`2020-01` to `2020-06` in the DataFrame), and then use hvPlot to plot the data. Do both time series indicate a common trend that’s consistent with this narrative?\n",
    "\n",
    "3. Create a new column in the DataFrame named “Lagged Search Trends” that offsets, or shifts, the search traffic by one hour. Create two additional columns:\n",
    "\n",
    "    * “Stock Volatility”, which holds an exponentially weighted four-hour rolling average of the company’s stock volatility\n",
    "\n",
    "    * “Hourly Stock Return”, which holds the percent change of the company's stock price on an hourly basis\n",
    "\n",
    "4. Review the time series correlation, and then answer the following question: Does a predictable relationship exist between the lagged search traffic and the stock volatility or between the lagged search traffic and the stock price returns?\n",
    "\n",
    "## Step 4: Create a Time Series Model with Prophet\n",
    "\n",
    "Now, you need to produce a time series model that analyzes and forecasts patterns in the hourly search data. To do so, complete the following steps:\n",
    "\n",
    "1. Set up the Google search data for a Prophet forecasting model.\n",
    "\n",
    "2. After estimating the model, plot the forecast. How's the near-term forecast for the popularity of MercadoLibre?\n",
    "\n",
    "3. Plot the individual time series components of the model to answer the following questions:\n",
    "\n",
    "    * What time of day exhibits the greatest popularity?\n",
    "\n",
    "    * Which day of the week gets the most search traffic?\n",
    "\n",
    "    * What's the lowest point for search traffic in the calendar year?\n",
    "\n",
    "## Step 5 (Optional): Forecast Revenue by Using Time Series Models\n",
    "\n",
    "A few weeks after your initial analysis, the finance group follows up to find out if you can help them solve a different problem. Your fame as a growth analyst in the company continues to grow!\n",
    "\n",
    "Specifically, the finance group wants a forecast of the total sales for the next quarter. This will dramatically increase their ability to plan budgets and to help guide expectations for the company investors.\n",
    "\n",
    "To do so, complete the following steps:\n",
    "\n",
    "1. Read in the daily historical sales (that is, revenue) figures, and then apply a Prophet model to the data.\n",
    "\n",
    "2. Interpret the model output to identify any seasonal patterns in the company's revenue. For example, what are the peak revenue days? (Mondays? Fridays? Something else?)\n",
    "\n",
    "3. Produce a sales forecast for the finance group. Give them a number for the expected total sales in the next quarter. Include the best- and worst-case scenarios to help them make better plans.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import the required libraries and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pystan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Getting requirements to build wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [20 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\ppate\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "      main()\n",
      "    File \"C:\\Users\\ppate\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\ppate\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "      return hook(config_settings)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\ppate\\AppData\\Local\\Temp\\pip-build-env-qhmejd3q\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 325, in get_requires_for_build_wheel\n",
      "      return self._get_build_requires(config_settings, requirements=['wheel'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\ppate\\AppData\\Local\\Temp\\pip-build-env-qhmejd3q\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 295, in _get_build_requires\n",
      "      self.run_setup()\n",
      "    File \"C:\\Users\\ppate\\AppData\\Local\\Temp\\pip-build-env-qhmejd3q\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 480, in run_setup\n",
      "      super(_BuildMetaLegacyBackend, self).run_setup(setup_script=setup_script)\n",
      "    File \"C:\\Users\\ppate\\AppData\\Local\\Temp\\pip-build-env-qhmejd3q\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 311, in run_setup\n",
      "      exec(code, locals())\n",
      "    File \"<string>\", line 122, in <module>\n",
      "  ModuleNotFoundError: No module named 'Cython'\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "Getting requirements to build wheel did not run successfully.\n",
      "exit code: 1\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading pystan-3.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting aiohttp<4.0,>=3.6 (from pystan)\n",
      "  Downloading aiohttp-3.9.1-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting clikit<0.7,>=0.6 (from pystan)\n",
      "  Downloading clikit-0.6.2-py2.py3-none-any.whl (91 kB)\n",
      "     ---------------------------------------- 0.0/91.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 91.8/91.8 kB 5.1 MB/s eta 0:00:00\n",
      "INFO: pip is looking at multiple versions of pystan to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pystan\n",
      "  Downloading pystan-3.6.0-py3-none-any.whl (13 kB)\n",
      "  Downloading pystan-3.5.0-py3-none-any.whl (13 kB)\n",
      "  Downloading pystan-3.4.0-py3-none-any.whl (13 kB)\n",
      "  Downloading pystan-3.3.0-py3-none-any.whl (13 kB)\n",
      "  Downloading pystan-3.2.0-py3-none-any.whl (13 kB)\n",
      "  Downloading pystan-3.1.1-py3-none-any.whl (13 kB)\n",
      "  Downloading pystan-3.1.0-py3-none-any.whl (13 kB)\n",
      "INFO: pip is still looking at multiple versions of pystan to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading pystan-3.0.2-py3-none-any.whl (13 kB)\n",
      "  Downloading pystan-3.0.1-py3-none-any.whl (12 kB)\n",
      "  Downloading pystan-3.0.0-py3-none-any.whl (12 kB)\n",
      "  Downloading pystan-2.19.1.1.tar.gz (16.2 MB)\n",
      "     ---------------------------------------- 0.0/16.2 MB ? eta -:--:--\n",
      "     ----- ---------------------------------- 2.2/16.2 MB 47.3 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 4.2/16.2 MB 53.8 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 5.9/16.2 MB 47.0 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 7.5/16.2 MB 43.5 MB/s eta 0:00:01\n",
      "     ------------------------ -------------- 10.2/16.2 MB 43.5 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 11.8/16.2 MB 43.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 13.8/16.2 MB 38.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 15.7/16.2 MB 40.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  16.2/16.2 MB 40.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  16.2/16.2 MB 40.9 MB/s eta 0:00:01\n",
      "     --------------------------------------- 16.2/16.2 MB 27.3 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "Collecting prophet\n",
      "  Downloading prophet-1.1.5-py3-none-win_amd64.whl.metadata (3.6 kB)\n",
      "Collecting cmdstanpy>=1.0.4 (from prophet)\n",
      "  Downloading cmdstanpy-1.2.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prophet) (1.26.0)\n",
      "Collecting matplotlib>=2.0.0 (from prophet)\n",
      "  Downloading matplotlib-3.8.2-cp311-cp311-win_amd64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: pandas>=1.0.4 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prophet) (2.1.1)\n",
      "Collecting holidays>=0.25 (from prophet)\n",
      "  Downloading holidays-0.37-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prophet) (4.66.1)\n",
      "Collecting importlib-resources (from prophet)\n",
      "  Downloading importlib_resources-6.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting stanio~=0.3.0 (from cmdstanpy>=1.0.4->prophet)\n",
      "  Downloading stanio-0.3.0-py3-none-any.whl.metadata (963 bytes)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from holidays>=0.25->prophet) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.2.0)\n",
      "Collecting cycler>=0.10 (from matplotlib>=2.0.0->prophet)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=2.0.0->prophet)\n",
      "  Downloading fonttools-4.46.0-cp311-cp311-win_amd64.whl.metadata (159 kB)\n",
      "     ---------------------------------------- 0.0/159.4 kB ? eta -:--:--\n",
      "     -------------------------------------- 159.4/159.4 kB 4.7 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=2.0.0->prophet)\n",
      "  Downloading kiwisolver-1.4.5-cp311-cp311-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (10.1.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=2.0.0->prophet)\n",
      "  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.0.4->prophet) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.0.4->prophet) (2023.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.36.1->prophet) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil->holidays>=0.25->prophet) (1.16.0)\n",
      "Downloading prophet-1.1.5-py3-none-win_amd64.whl (13.3 MB)\n",
      "   ---------------------------------------- 0.0/13.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/13.3 MB 7.9 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.5/13.3 MB 5.6 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.7/13.3 MB 4.6 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.8/13.3 MB 4.7 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.2/13.3 MB 5.3 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.0/13.3 MB 7.6 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.3/13.3 MB 10.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.7/13.3 MB 13.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.3/13.3 MB 15.5 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.9/13.3 MB 17.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.6/13.3 MB 19.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.0/13.3 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.6/13.3 MB 19.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.6/13.3 MB 25.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.3/13.3 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.3/13.3 MB 24.2 MB/s eta 0:00:00\n",
      "Downloading cmdstanpy-1.2.0-py3-none-any.whl (93 kB)\n",
      "   ---------------------------------------- 0.0/93.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 93.0/93.0 kB 5.2 MB/s eta 0:00:00\n",
      "Downloading holidays-0.37-py3-none-any.whl (851 kB)\n",
      "   ---------------------------------------- 0.0/852.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 852.0/852.0 kB 27.2 MB/s eta 0:00:00\n",
      "Downloading matplotlib-3.8.2-cp311-cp311-win_amd64.whl (7.6 MB)\n",
      "   ---------------------------------------- 0.0/7.6 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 1.6/7.6 MB 52.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 3.4/7.6 MB 43.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.9/7.6 MB 38.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 6.7/7.6 MB 39.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.6 MB 37.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.6/7.6 MB 32.6 MB/s eta 0:00:00\n",
      "Downloading importlib_resources-6.1.1-py3-none-any.whl (33 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.46.0-cp311-cp311-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 1.5/2.2 MB 46.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 34.9 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.5-cp311-cp311-win_amd64.whl (56 kB)\n",
      "   ---------------------------------------- 0.0/56.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 56.1/56.1 kB 3.1 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "   ---------------------------------------- 0.0/103.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 103.1/103.1 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading stanio-0.3.0-py3-none-any.whl (6.2 kB)\n",
      "Installing collected packages: stanio, pyparsing, kiwisolver, importlib-resources, fonttools, cycler, matplotlib, holidays, cmdstanpy, prophet\n",
      "Successfully installed cmdstanpy-1.2.0 cycler-0.12.1 fonttools-4.46.0 holidays-0.37 importlib-resources-6.1.1 kiwisolver-1.4.5 matplotlib-3.8.2 prophet-1.1.5 pyparsing-3.1.1 stanio-0.3.0\n",
      "Requirement already satisfied: hvplot in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: bokeh>=1.0.0 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from hvplot) (3.3.1)\n",
      "Requirement already satisfied: colorcet>=2 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from hvplot) (3.0.1)\n",
      "Requirement already satisfied: holoviews>=1.11.0 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from hvplot) (1.18.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from hvplot) (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from hvplot) (1.26.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from hvplot) (23.2)\n",
      "Requirement already satisfied: panel>=0.11.0 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from hvplot) (1.3.2)\n",
      "Requirement already satisfied: param<3.0,>=1.9.0 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from hvplot) (2.0.1)\n",
      "Requirement already satisfied: Jinja2>=2.9 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bokeh>=1.0.0->hvplot) (3.1.2)\n",
      "Requirement already satisfied: contourpy>=1 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bokeh>=1.0.0->hvplot) (1.2.0)\n",
      "Requirement already satisfied: pillow>=7.1.0 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bokeh>=1.0.0->hvplot) (10.1.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bokeh>=1.0.0->hvplot) (6.0.1)\n",
      "Requirement already satisfied: tornado>=5.1 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bokeh>=1.0.0->hvplot) (6.3.3)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bokeh>=1.0.0->hvplot) (2023.10.1)\n",
      "Requirement already satisfied: pyct>=0.4.4 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from colorcet>=2->hvplot) (0.5.0)\n",
      "Requirement already satisfied: pyviz-comms>=0.7.4 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from holoviews>=1.11.0->hvplot) (3.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->hvplot) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->hvplot) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->hvplot) (2023.3)\n",
      "Requirement already satisfied: markdown in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from panel>=0.11.0->hvplot) (3.5.1)\n",
      "Requirement already satisfied: markdown-it-py in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from panel>=0.11.0->hvplot) (3.0.0)\n",
      "Requirement already satisfied: linkify-it-py in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from panel>=0.11.0->hvplot) (2.0.2)\n",
      "Requirement already satisfied: mdit-py-plugins in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from panel>=0.11.0->hvplot) (0.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from panel>=0.11.0->hvplot) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.48.0 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from panel>=0.11.0->hvplot) (4.66.1)\n",
      "Requirement already satisfied: bleach in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from panel>=0.11.0->hvplot) (6.1.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from panel>=0.11.0->hvplot) (4.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Jinja2>=2.9->bokeh>=1.0.0->hvplot) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->hvplot) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.48.0->panel>=0.11.0->hvplot) (0.4.6)\n",
      "Requirement already satisfied: webencodings in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bleach->panel>=0.11.0->hvplot) (0.5.1)\n",
      "Requirement already satisfied: uc-micro-py in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from linkify-it-py->panel>=0.11.0->hvplot) (1.0.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py->panel>=0.11.0->hvplot) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->panel>=0.11.0->hvplot) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->panel>=0.11.0->hvplot) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->panel>=0.11.0->hvplot) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->panel>=0.11.0->hvplot) (2023.7.22)\n",
      "Requirement already satisfied: holoviews in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.18.1)\n",
      "Requirement already satisfied: param<3.0,>=1.12.0 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from holoviews) (2.0.1)\n",
      "Requirement already satisfied: numpy>=1.0 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from holoviews) (1.26.0)\n",
      "Requirement already satisfied: pyviz-comms>=0.7.4 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from holoviews) (3.0.0)\n",
      "Requirement already satisfied: panel>=1.0 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from holoviews) (1.3.2)\n",
      "Requirement already satisfied: colorcet in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from holoviews) (3.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from holoviews) (23.2)\n",
      "Requirement already satisfied: pandas>=0.20.0 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from holoviews) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.20.0->holoviews) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.20.0->holoviews) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.20.0->holoviews) (2023.3)\n",
      "Requirement already satisfied: bokeh<3.4.0,>=3.2.0 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from panel>=1.0->holoviews) (3.3.1)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from panel>=1.0->holoviews) (2023.10.1)\n",
      "Requirement already satisfied: markdown in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from panel>=1.0->holoviews) (3.5.1)\n",
      "Requirement already satisfied: markdown-it-py in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from panel>=1.0->holoviews) (3.0.0)\n",
      "Requirement already satisfied: linkify-it-py in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from panel>=1.0->holoviews) (2.0.2)\n",
      "Requirement already satisfied: mdit-py-plugins in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from panel>=1.0->holoviews) (0.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from panel>=1.0->holoviews) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.48.0 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from panel>=1.0->holoviews) (4.66.1)\n",
      "Requirement already satisfied: bleach in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from panel>=1.0->holoviews) (6.1.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from panel>=1.0->holoviews) (4.8.0)\n",
      "Requirement already satisfied: pyct>=0.4.4 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from colorcet->holoviews) (0.5.0)\n",
      "Requirement already satisfied: Jinja2>=2.9 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bokeh<3.4.0,>=3.2.0->panel>=1.0->holoviews) (3.1.2)\n",
      "Requirement already satisfied: contourpy>=1 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bokeh<3.4.0,>=3.2.0->panel>=1.0->holoviews) (1.2.0)\n",
      "Requirement already satisfied: pillow>=7.1.0 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bokeh<3.4.0,>=3.2.0->panel>=1.0->holoviews) (10.1.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bokeh<3.4.0,>=3.2.0->panel>=1.0->holoviews) (6.0.1)\n",
      "Requirement already satisfied: tornado>=5.1 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bokeh<3.4.0,>=3.2.0->panel>=1.0->holoviews) (6.3.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.20.0->holoviews) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.48.0->panel>=1.0->holoviews) (0.4.6)\n",
      "Requirement already satisfied: webencodings in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bleach->panel>=1.0->holoviews) (0.5.1)\n",
      "Requirement already satisfied: uc-micro-py in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from linkify-it-py->panel>=1.0->holoviews) (1.0.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py->panel>=1.0->holoviews) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->panel>=1.0->holoviews) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->panel>=1.0->holoviews) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->panel>=1.0->holoviews) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->panel>=1.0->holoviews) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ppate\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Jinja2>=2.9->bokeh<3.4.0,>=3.2.0->panel>=1.0->holoviews) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "# Install the required libraries\n",
    "!pip install pystan\n",
    "!pip install prophet\n",
    "!pip install hvplot\n",
    "!pip install holoviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries and dependencies\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "from prophet import Prophet\n",
    "import hvplot.pandas\n",
    "import datetime as dt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Find Unusual Patterns in Hourly Google Search Traffic\n",
    "\n",
    "The data science manager asks if the Google search traffic for the company links to any financial events at the company. Or, does the search traffic data just present random noise? To answer this question, pick out any unusual patterns in the Google search data for the company, and connect them to the corporate financial events.\n",
    "\n",
    "To do so, complete the following steps:\n",
    "\n",
    "1. Read the search data into a DataFrame, and then slice the data to just the month of May 2020. (During this month, MercadoLibre released its quarterly financial results.) Use hvPlot to visualize the results. Do any unusual patterns exist?\n",
    "\n",
    "2. Calculate the total search traffic for the month, and then compare the value to the monthly median across all months. Did the Google search traffic increase during the month that MercadoLibre released its financial results?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Read the search data into a DataFrame, and then slice the data to just the month of May 2020. (During this month, MercadoLibre released its quarterly financial results.) Use hvPlot to visualize the results. Do any unusual patterns exist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\Resources\\\\google_hourly_search_trends.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Upload the \"google_hourly_search_trends.csv\" file into Colab, then store in a Pandas DataFrame\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Set the \"Date\" column as the Datetime Index.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#from google.colab import files\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#uploaded = files.upload()\u001b[39;00m\n\u001b[0;32m      6\u001b[0m file_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mResources\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mgoogle_hourly_search_trends.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m df_mercado_trends \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#.index([\"Date\"])\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Review the first and last five rows of the DataFrame\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#df_mercado_trends.head()\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#df_mercado_trends.tail()\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\Resources\\\\google_hourly_search_trends.csv'"
     ]
    }
   ],
   "source": [
    "# Upload the \"google_hourly_search_trends.csv\" file into Colab, then store in a Pandas DataFrame\n",
    "# Set the \"Date\" column as the Datetime Index.\n",
    "\n",
    "#from google.colab import files\n",
    "#uploaded = files.upload()\n",
    "file_path = Path(\"..\\Resources\\google_hourly_search_trends.csv\")\n",
    "df_mercado_trends = pd.read_csv(file_path)\n",
    "#.index([\"Date\"])\n",
    "\n",
    "# Review the first and last five rows of the DataFrame\n",
    "#df_mercado_trends.head()\n",
    "#df_mercado_trends.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_mercado_trends' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Review the data types of the DataFrame using the info function\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdf_mercado_trends\u001b[49m\u001b[38;5;241m.\u001b[39minfo()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_mercado_trends' is not defined"
     ]
    }
   ],
   "source": [
    "# Review the data types of the DataFrame using the info function\n",
    "df_mercado_trends.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holoviews extension to render hvPlots in Colab\n",
    "hv.extension('bokeh')\n",
    "\n",
    "# Slice the DataFrame to just the month of May 2020\n",
    "df_may_2020 = # YOUR CODE HERE\n",
    "\n",
    "# Use hvPlot to visualize the data for May 2020\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Calculate the total search traffic for the month, and then compare the value to the monthly median across all months. Did the Google search traffic increase during the month that MercadoLibre released its financial results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of the total search traffic for May 2020\n",
    "traffic_may_2020 = # YOUR CODE HERE\n",
    "\n",
    "# View the traffic_may_2020 value\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcluate the monhtly median search traffic across all months \n",
    "# Group the DataFrame by index year and then index month, chain the sum and then the median functions\n",
    "median_monthly_traffic = # YOUR CODE HERE\n",
    "\n",
    "# View the median_monthly_traffic value\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the seach traffic for the month of May 2020 to the overall monthly median value\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer the following question: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Did the Google search traffic increase during the month that MercadoLibre released its financial results?\n",
    "\n",
    "**Answer:** # YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Mine the Search Traffic Data for Seasonality\n",
    "\n",
    "Marketing realizes that they can use the hourly search data, too. If they can track and predict interest in the company and its platform for any time of day, they can focus their marketing efforts around the times that have the most traffic. This will get a greater return on investment (ROI) from their marketing budget.\n",
    "\n",
    "To that end, you want to mine the search traffic data for predictable seasonal patterns of interest in the company. To do so, complete the following steps:\n",
    "\n",
    "1. Group the hourly search data to plot the average traffic by the day of the week (for example, Monday vs. Friday).\n",
    "\n",
    "2. Using hvPlot, visualize this traffic as a heatmap, referencing the `index.hour` as the x-axis and the `index.dayofweek` as the y-axis. Does any day-of-week effect that you observe concentrate in just a few hours of that day?\n",
    "\n",
    "3. Group the search data by the week of the year. Does the search traffic tend to increase during the winter holiday period (weeks 40 through 52)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Group the hourly search data to plot the average traffic by the day of the week (for example, Monday vs. Friday)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holoviews extension to render hvPlots in Colab\n",
    "hv.extension('bokeh')\n",
    "\n",
    "# Group the hourly search data to plot (use hvPlot) the average traffic by the day of week \n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Using hvPlot, visualize this traffic as a heatmap, referencing the `index.hour` as the x-axis and the `index.dayofweek` as the y-axis. Does any day-of-week effect that you observe concentrate in just a few hours of that day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holoviews extension to render hvPlots in Colab\n",
    "hv.extension('bokeh')\n",
    "\n",
    "# Use hvPlot to visualize the hour of the day and day of week search traffic as a heatmap.\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer the following question:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Does any day-of-week effect that you observe concentrate in just a few hours of that day?\n",
    "\n",
    "**Answer:** # YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Group the search data by the week of the year. Does the search traffic tend to increase during the winter holiday period (weeks 40 through 52)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holoviews extension to render hvPlots in Colab\n",
    "hv.extension('bokeh')\n",
    "\n",
    "# Group the hourly search data to plot (use hvPlot) the average traffic by the week of the year\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer the following question:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Does the search traffic tend to increase during the winter holiday period (weeks 40 through 52)?\n",
    "\n",
    "**Answer:** # YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Relate the Search Traffic to Stock Price Patterns\n",
    "\n",
    "You mention your work on the search traffic data during a meeting with people in the finance group at the company. They want to know if any relationship between the search data and the company stock price exists, and they ask if you can investigate.\n",
    "\n",
    "To do so, complete the following steps:\n",
    "\n",
    "1. Read in and plot the stock price data. Concatenate the stock price data to the search data in a single DataFrame.\n",
    "\n",
    "2. Market events emerged during the year of 2020 that many companies found difficult. But, after the initial shock to global financial markets, new customers and revenue increased for e-commerce platforms. Slice the data to just the first half of 2020 (`2020-01` to `2020-06` in the DataFrame), and then use hvPlot to plot the data. Do both time series indicate a common trend that’s consistent with this narrative?\n",
    "\n",
    "3. Create a new column in the DataFrame named “Lagged Search Trends” that offsets, or shifts, the search traffic by one hour. Create two additional columns:\n",
    "\n",
    "    * “Stock Volatility”, which holds an exponentially weighted four-hour rolling average of the company’s stock volatility\n",
    "\n",
    "    * “Hourly Stock Return”, which holds the percent change of the company's stock price on an hourly basis\n",
    "\n",
    "4. Review the time series correlation, and then answer the following question: Does a predictable relationship exist between the lagged search traffic and the stock volatility or between the lagged search traffic and the stock price returns?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Read in and plot the stock price data. Concatenate the stock price data to the search data in a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the \"mercado_stock_price.csv\" file into Colab, then store in a Pandas DataFrame\n",
    "# Set the \"date\" column as the Datetime Index.\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "df_mercado_stock = # YOUR CODE HERE\n",
    "\n",
    "# View the first and last five rows of the DataFrame\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holoviews extension to render hvPlots in Colab\n",
    "hv.extension('bokeh')\n",
    "\n",
    "# Use hvPlot to visualize the closing price of the df_mercado_stock DataFrame\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the df_mercado_stock DataFrame with the df_mercado_trends DataFrame\n",
    "# Concatenate the DataFrame by columns (axis=1), and drop and rows with only one column of data\n",
    "mercado_stock_trends_df = # YOUR CODE HERE\n",
    "\n",
    "# View the first and last five rows of the DataFrame\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Market events emerged during the year of 2020 that many companies found difficult. But, after the initial shock to global financial markets, new customers and revenue increased for e-commerce platforms. Slice the data to just the first half of 2020 (`2020-01` to `2020-06` in the DataFrame), and then use hvPlot to plot the data. Do both time series indicate a common trend that’s consistent with this narrative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the combined dataframe, slice to just the first half of 2020 (2020-01 through 2020-06) \n",
    "first_half_2020 = # YOUR CODE HERE\n",
    "\n",
    "# View the first and last five rows of first_half_2020 DataFrame\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holoviews extension to render hvPlots in Colab\n",
    "hv.extension('bokeh')\n",
    "\n",
    "# Use hvPlot to visualize the close and Search Trends data\n",
    "# Plot each column on a separate axes using the following syntax\n",
    "# `hvplot(shared_axes=False, subplots=True).cols(1)`\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer the following question:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Do both time series indicate a common trend that’s consistent with this narrative?\n",
    "\n",
    "**Answer:** # YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Create a new column in the DataFrame named “Lagged Search Trends” that offsets, or shifts, the search traffic by one hour. Create two additional columns:\n",
    "\n",
    "* “Stock Volatility”, which holds an exponentially weighted four-hour rolling average of the company’s stock volatility\n",
    "\n",
    "* “Hourly Stock Return”, which holds the percent change of the company's stock price on an hourly basis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column in the mercado_stock_trends_df DataFrame called Lagged Search Trends\n",
    "# This column should shift the Search Trends information by one hour\n",
    "mercado_stock_trends_df['Lagged Search Trends'] = # YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column in the mercado_stock_trends_df DataFrame called Stock Volatility\n",
    "# This column should calculate the standard deviation of the closing stock price return data over a 4 period rolling window\n",
    "mercado_stock_trends_df['Stock Volatility'] = # YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holoviews extension to render hvPlots in Colab\n",
    "hv.extension('bokeh')\n",
    "\n",
    "# Use hvPlot to visualize the stock volatility\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution Note:** Note how volatility spiked, and tended to stay high, during the first half of 2020. This is a common characteristic of volatility in stock returns worldwide: high volatility days tend to be followed by yet more high volatility days. When it rains, it pours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column in the mercado_stock_trends_df DataFrame called Hourly Stock Return\n",
    "# This column should calculate hourly return percentage of the closing price\n",
    "mercado_stock_trends_df['Hourly Stock Return'] = # YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first and last five rows of the mercado_stock_trends_df DataFrame\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Review the time series correlation, and then answer the following question: Does a predictable relationship exist between the lagged search traffic and the stock volatility or between the lagged search traffic and the stock price returns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct correlation table of Stock Volatility, Lagged Search Trends, and Hourly Stock Return\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer the following question:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Does a predictable relationship exist between the lagged search traffic and the stock volatility or between the lagged search traffic and the stock price returns?\n",
    "\n",
    "**Answer:** # YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create a Time Series Model with Prophet\n",
    "\n",
    "Now, you need to produce a time series model that analyzes and forecasts patterns in the hourly search data. To do so, complete the following steps:\n",
    "\n",
    "1. Set up the Google search data for a Prophet forecasting model.\n",
    "\n",
    "2. After estimating the model, plot the forecast. How's the near-term forecast for the popularity of MercadoLibre?\n",
    "\n",
    "3. Plot the individual time series components of the model to answer the following questions:\n",
    "\n",
    "    * What time of day exhibits the greatest popularity?\n",
    "\n",
    "    * Which day of the week gets the most search traffic?\n",
    "\n",
    "    * What's the lowest point for search traffic in the calendar year?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Set up the Google search data for a Prophet forecasting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the df_mercado_trends DataFrame, reset the index so the date information is no longer the index\n",
    "mercado_prophet_df = # YOUR CODE HERE\n",
    "\n",
    "# Label the columns ds and y so that the syntax is recognized by Prophet\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Drop an NaN values from the prophet_df DataFrame\n",
    "mercado_prophet_df = # YOUR CODE HERE\n",
    "\n",
    "# View the first and last five rows of the mercado_prophet_df DataFrame\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the Prophet function, store as an object\n",
    "model_mercado_trends = # YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the time-series model.\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a future dataframe to hold predictions\n",
    "# Make the prediction go out as far as 2000 hours (approx 80 days)\n",
    "future_mercado_trends = # YOUR CODE HERE\n",
    "\n",
    "# View the last five rows of the future_mercado_trends DataFrame\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the predictions for the trend data using the future_mercado_trends DataFrame\n",
    "forecast_mercado_trends = # YOUR CODE HERE\n",
    "\n",
    "# Display the first five rows of the forecast_mercado_trends DataFrame\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: After estimating the model, plot the forecast. How's the near-term forecast for the popularity of MercadoLibre?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Prophet predictions for the Mercado trends data\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer the following question:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:**  How's the near-term forecast for the popularity of MercadoLibre?\n",
    "\n",
    "**Answer:** # YOUR ANSWER HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Plot the individual time series components of the model to answer the following questions:\n",
    "\n",
    "* What time of day exhibits the greatest popularity?\n",
    "\n",
    "* Which day of the week gets the most search traffic?\n",
    "\n",
    "* What's the lowest point for search traffic in the calendar year?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index in the forecast_mercado_trends DataFrame to the ds datetime column\n",
    "forecast_mercado_trends = # YOUR CODE HERE\n",
    "\n",
    "# View the only the yhat,yhat_lower and yhat_upper columns from the DataFrame\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solutions Note: `yhat` represents the most likely (average) forecast, whereas `yhat_lower` and `yhat_upper` represents the worst and best case prediction (based on what are known as 95% confidence intervals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holoviews extension to render hvPlots in Colab\n",
    "hv.extension('bokeh')\n",
    "\n",
    "# From the forecast_mercado_trends DataFrame, use hvPlot to visualize\n",
    "#  the yhat, yhat_lower, and yhat_upper columns over the last 2000 hours \n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index in the forecast_mercado_trends DataFrame\n",
    "forecast_mercado_trends = # YOUR CODE HERE\n",
    "\n",
    "# Use the plot_components function to visualize the forecast results \n",
    "# for the forecast_canada DataFrame \n",
    "figures_mercado_trends = # YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What time of day exhibits the greatest popularity?\n",
    "\n",
    "**Answer:** # YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Which day of week gets the most search traffic? \n",
    "   \n",
    "**Answer:** # YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What's the lowest point for search traffic in the calendar year?\n",
    "\n",
    "**Answer:** # YOUR ANSWER HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 (Optional): Forecast Revenue by Using Time Series Models\n",
    "\n",
    "A few weeks after your initial analysis, the finance group follows up to find out if you can help them solve a different problem. Your fame as a growth analyst in the company continues to grow!\n",
    "\n",
    "Specifically, the finance group wants a forecast of the total sales for the next quarter. This will dramatically increase their ability to plan budgets and to help guide expectations for the company investors.\n",
    "\n",
    "To do so, complete the following steps:\n",
    "\n",
    "1. Read in the daily historical sales (that is, revenue) figures, and then apply a Prophet model to the data. The daily sales figures are quoted in millions of USD dollars.\n",
    "\n",
    "2. Interpret the model output to identify any seasonal patterns in the company's revenue. For example, what are the peak revenue days? (Mondays? Fridays? Something else?)\n",
    "\n",
    "3. Produce a sales forecast for the finance group. Give them a number for the expected total sales in the next quarter. Include the best- and worst-case scenarios to help them make better plans.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Read in the daily historical sales (that is, revenue) figures, and then apply a Prophet model to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the \"mercado_daily_revenue.csv\" file into Colab, then store in a Pandas DataFrame\n",
    "# Set the \"date\" column as the DatetimeIndex\n",
    "# Sales are quoted in millions of US dollars\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "df_mercado_sales = # YOUR CODE HERE\n",
    "\n",
    "# Review the DataFrame\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holoviews extension to render hvPlots in Colab\n",
    "hv.extension('bokeh')\n",
    "\n",
    "# Use hvPlot to visualize the daily sales figures \n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a Facebook Prophet model to the data.\n",
    "\n",
    "# Set up the dataframe in the neccessary format:\n",
    "# Reset the index so that date becomes a column in the DataFrame\n",
    "mercado_sales_prophet_df = # YOUR CODE HERE\n",
    "\n",
    "# Adjust the columns names to the Prophet syntax\n",
    "mercado_sales_prophet_df.columns = # YOUR CODE HERE\n",
    "\n",
    "# Visualize the DataFrame\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "mercado_sales_prophet_model = # YOUR CODE HERE\n",
    "\n",
    "# Fit the model\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict sales for 90 days (1 quarter) out into the future.\n",
    "\n",
    "# Start by making a future dataframe\n",
    "mercado_sales_prophet_future = # YOUR CODE HERE\n",
    "\n",
    "# Display the last five rows of the future DataFrame\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for the sales each day over the next quarter\n",
    "mercado_sales_prophet_forecast = # YOUR CODE HERE\n",
    "\n",
    "# Display the first 5 rows of the resulting DataFrame\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Interpret the model output to identify any seasonal patterns in the company's revenue. For example, what are the peak revenue days? (Mondays? Fridays? Something else?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the plot_components function to analyze seasonal patterns in the company's revenue\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer the following question:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** For example, what are the peak revenue days? (Mondays? Fridays? Something else?)\n",
    "\n",
    "**Answer:** # YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Produce a sales forecast for the finance group. Give them a number for the expected total sales in the next quarter. Include the best- and worst-case scenarios to help them make better plans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predictions for the Mercado sales\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the mercado_sales_prophet_forecast DataFrame, set the ds column as the DataFrame Index\n",
    "mercado_sales_prophet_forecast = # YOUR CODE HERE\n",
    "\n",
    "# Display the first and last five rows of the DataFrame\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a sales forecast for the finance division\n",
    "# giving them a number for expected total sales next quarter.\n",
    "# Provide best case (yhat_upper), worst case (yhat_lower), and most likely (yhat) scenarios.\n",
    "\n",
    "# Create a forecast_quarter Dataframe for the period 2020-07-01 to 2020-09-30\n",
    "# The DataFrame should include the columns yhat_upper, yhat_lower, and yhat\n",
    "mercado_sales_forecast_quarter = # YOUR CODE HERE\n",
    "\n",
    "# Update the column names for the forecast_quarter DataFrame\n",
    "# to match what the finance division is looking for \n",
    "mercado_sales_forecast_quarter = # YOUR CODE HERE\n",
    "\n",
    "# Review the last five rows of the DataFrame\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displayed the summed values for all the rows in the forecast_quarter DataFrame\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on the forecast information generated above, produce a sales forecast for the finance division, giving them a number for expected total sales next quarter. Include best and worst case scenarios, to better help the finance team plan.\n",
    "\n",
    "**Answer:** # YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
